{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: SemEval2017 Task 4 - Sentiment Analysis\n",
    "## Classification and Regression Approaches with Optimisations\n",
    "\n",
    "**Author:** Samid  \n",
    "**Course:** CMT122 - Machine Learning for NLP  \n",
    "**Academic Year:** 2025/2026\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction & Objectives](#section1)\n",
    "2. [Imports & Setup](#section2)\n",
    "3. [Data Loading & Exploration](#section3)\n",
    "4. [Text Preprocessing](#section4)\n",
    "5. [Train-Test Split](#section5)\n",
    "6. [Feature Engineering (TF-IDF)](#section6)\n",
    "7. [Classification Experiments](#section7)\n",
    "8. [Regression Experiments](#section8)\n",
    "10. [Detailed Performance Analysis](#section10)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction & Objectives <a id='section1'></a>\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "This notebook addresses **SemEval2017 Task 4: Sentiment Analysis in Twitter**, approaching the problem through two methods:\n",
    "\n",
    "1. **Classification**: Predicting discrete sentiment labels (positive, negative, neutral)\n",
    "2. **Regression**: Predicting continuous sentiment intensity scores (-1.0 to 1.0)\n",
    "\n",
    "### Dataset\n",
    "\n",
    "- **Source**: SemEval2017 Task 4 Twitter sentiment dataset\n",
    "- **Size**: 19,699 tweets\n",
    "- **Classes**: 3 (positive, negative, neutral)\n",
    "- **Format**: CSV with columns `text` (tweet content) and `label` (sentiment)\n",
    "\n",
    "### Objectives\n",
    "\n",
    "1. Preprocess Twitter text (clean, normalize)\n",
    "2. Extract TF-IDF features with optimal parameters\n",
    "3. Train and compare multiple classification models\n",
    "4. Train and compare multiple regression models\n",
    "5. Evaluate performance using appropriate metrics\n",
    "6. Document best models for PDF report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports & Setup <a id='section2'></a>\n",
    "\n",
    "### Required Libraries\n",
    "\n",
    "This section imports all necessary Python libraries for data processing, feature extraction, modeling, and evaluation.\n",
    "\n",
    "**Library Purposes:**\n",
    "- `numpy`, `pandas`: Data manipulation and array operations\n",
    "- `nltk`: Natural language processing toolkit for text preprocessing\n",
    "- `re`: Regular expressions for text cleaning\n",
    "- `sklearn`: Machine learning models, feature extraction, and evaluation metrics\n",
    "- `warnings`: Suppress non-critical warnings for cleaner output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports and setup complete\n"
     ]
    }
   ],
   "source": [
    "# Part 1 and 2: SemEval2017 Task 4 - Sentiment Analysis (High Accuracy & Compliant)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "\n",
    "# NLTK Setup\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Exploration <a id='section3'></a>\n",
    "\n",
    "### Data Loading Function\n",
    "\n",
    "**Function Purpose:**  \n",
    "Load the SemEval2017 dataset and perform initial text cleaning to prepare for analysis.\n",
    "\n",
    "**Input:**  \n",
    "- `file_path` (str): Path to the CSV file containing tweets and labels\n",
    "\n",
    "**Output:**  \n",
    "- `DataFrame`: Pandas DataFrame with columns:\n",
    "  - `text`: Original tweet text\n",
    "  - `label`: Sentiment label (positive/negative/neutral)\n",
    "  - `cleaned_text`: Preprocessed tweet text\n",
    "\n",
    "**Justification of Cleaning methodology?**\n",
    "1. **Lowercase**: Ensures \"Happy\" and \"happy\" are treated as the same word\n",
    "2. **URL removal**: URLs don't carry sentiment information\n",
    "3. **Mention removal**: @username references are not sentiment-bearing\n",
    "4. **Hashtag processing**: Keeps hashtag text (e.g., #happy → happy) as it often contains sentiment\n",
    "5. **Punctuation normalization**: Reduces excessive punctuation (!!! → !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 19699 samples\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "neutral     9409\n",
      "positive    7059\n",
      "negative    3231\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess\n",
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    def clean_text(text):\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        text = str(text).lower()\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        # Remove mentions\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "        # Remove hashtags but keep text\n",
    "        text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "        # NEW: Remove excessive punctuation\n",
    "        text = re.sub(r'([!?.]){2,}', r'\\1', text)\n",
    "        # NEW: Remove numbers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        return text\n",
    "    \n",
    "    df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "data_path = '/home/samidunix/projects/CMT122/SemEval2017 Task4_ Sentiment_Analysis.csv'\n",
    "df = load_and_preprocess_data(data_path)\n",
    "\n",
    "print(f\"Dataset loaded: {len(df)} samples\")\n",
    "print(f\"\\nLabel distribution:\\n{df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split <a id='section5'></a>\n",
    "\n",
    "### Why Split the Data?\n",
    "\n",
    "I divide the dataset into **training** (80%) and **test** (20%) sets:\n",
    "- **Training set**: Used to fit the model parameters\n",
    "- **Test set**: Used ONLY for final evaluation (never seen during training)\n",
    "\n",
    "**Justification of Stratified Split?**  \n",
    "The dataset is imbalanced (47.8% neutral, 35.8% positive, 16.4% negative). Stratified splitting ensures both train and test sets maintain the same class proportions, preventing bias in evaluation.\n",
    "\n",
    "**Random State:**  \n",
    "Setting `random_state=42` helps ensures reproducibility - the same split every time the code is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 15759, Test: 3940\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "# Prepare labels\n",
    "X_train_text = df_train['cleaned_text'].values\n",
    "X_test_text = df_test['cleaned_text'].values\n",
    "y_train_class = df_train['label'].values\n",
    "y_test_class = df_test['label'].values\n",
    "\n",
    "label_to_score = {'positive': 1.0, 'neutral': 0.0, 'negative': -1.0}\n",
    "y_train_reg = df_train['label'].map(label_to_score).values\n",
    "y_test_reg = df_test['label'].map(label_to_score).values\n",
    "\n",
    "print(f\"Training: {len(df_train)}, Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering: TF-IDF Vectorization <a id='section6'></a>\n",
    "\n",
    "### What is TF-IDF?\n",
    "\n",
    "**TF-IDF** (Term Frequency-Inverse Document Frequency) is a numerical representation of text that balances:\n",
    "- **TF (Term Frequency)**: How often a word appears in a document\n",
    "- **IDF (Inverse Document Frequency)**: How rare/common a word is across all documents\n",
    "\n",
    "**Formula:**  \n",
    "TF-IDF(word, doc) = TF(word, doc) × IDF(word)\n",
    "\n",
    "**Why use TF-IDF for Sentiment Analysis?**\n",
    "- Downweights common words (\"the\", \"is\") that don't carry sentiment\n",
    "- Emphasizes distinctive sentiment words (\"love\", \"hate\", \"terrible\")\n",
    "- Creates sparse, high-dimensional feature vectors suitable for linear models\n",
    "\n",
    "### Optimised Parameter Choices\n",
    "\n",
    "These parameters were chosen through experimentation to maximize performance:\n",
    "\n",
    "1. **`max_features=8000`**: Vocabulary size (increased from baseline 5000)\n",
    "   - More features capture more nuanced sentiment expressions\n",
    "   - Trade-off: Computational cost vs. accuracy\n",
    "\n",
    "2. **`ngram_range=(1, 3)`**: Include unigrams, bigrams, and trigrams\n",
    "   - Unigrams: \"happy\", \"sad\"\n",
    "   - Bigrams: \"not happy\", \"very sad\"\n",
    "   - Trigrams: \"not very happy\"\n",
    "   - Captures negation and intensifiers crucial for sentiment\n",
    "\n",
    "3. **`stop_words='english'`**: Remove common English stopwords\n",
    "   - Filters out \"the\", \"is\", \"at\", etc.\n",
    "   - Reduces noise in feature space\n",
    "\n",
    "4. **`min_df=2`**: Word must appear in at least 2 documents\n",
    "   - Removes typos and rare words\n",
    "   - Balances vocabulary coverage with noise reduction\n",
    "\n",
    "5. **`max_df=0.7`**: Word must appear in at most 70% of documents\n",
    "   - Removes overly common words not filtered by stopwords\n",
    "   - Keeps moderately common sentiment words\n",
    "\n",
    "6. **`sublinear_tf=True`**: Apply logarithmic scaling to term frequencies\n",
    "   - Formula: 1 + log(TF) instead of TF\n",
    "   - Reduces impact of extremely frequent words within a document\n",
    "\n",
    "7. **`use_idf=True`, `smooth_idf=True`**: Enable IDF weighting with smoothing\n",
    "   - Smooth IDF prevents division by zero for new words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix: (15759, 8000)\n"
     ]
    }
   ],
   "source": [
    "# IMPROVED TF-IDF with better parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=8000,              # Increased from 5000\n",
    "    ngram_range=(1, 3),             # Include trigrams\n",
    "    stop_words='english',\n",
    "    min_df=2,                       # Lowered from 3\n",
    "    max_df=0.7,                     # Lowered from 0.9\n",
    "    sublinear_tf=True,              # Log scaling\n",
    "    use_idf=True,\n",
    "    smooth_idf=True\n",
    ")\n",
    "\n",
    "X_train_features = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_test_features = tfidf_vectorizer.transform(X_test_text)\n",
    "\n",
    "print(f\"Feature matrix: {X_train_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification Experiments <a id='section7'></a>\n",
    "\n",
    "### Classification Task Overview\n",
    "\n",
    "**Goal:** Predict discrete sentiment labels (positive, negative, neutral) for tweets\n",
    "\n",
    "**Evaluation Metric:** Accuracy (proportion of correct predictions)\n",
    "\n",
    "### Models to Compare\n",
    "\n",
    "I tested four different classification models to find the best performer:\n",
    "\n",
    "1. **LinearSVC (C=0.5)**: Fast linear SVM with moderate regularisation\n",
    "   - **Why?** Efficient for high-dimensional sparse text data\n",
    "   - **C parameter**: Lower C = stronger regularisation = simpler model\n",
    "\n",
    "2. **LinearSVC (C=1.0)**: Fast linear SVM with standard regularisation\n",
    "   - **Why?** Baseline configuration, balanced regularisation\n",
    "\n",
    "3. **Logistic Regression (C=1.0)**: Probabilistic linear classifier\n",
    "   - **Why?** Provides probability estimates, interpretable coefficients\n",
    "   - **Advantage**: Can output confidence scores\n",
    "\n",
    "4. **SVC with RBF kernel**: Non-linear SVM\n",
    "   - **Why?** Can capture non-linear decision boundaries\n",
    "   - **Trade-off**: Slower training, may not be needed for text\n",
    "\n",
    "5. **SVC with Linear kernel**: Standard linear SVM\n",
    "   - **Why?** Slower than LinearSVC but sometimes more accurate\n",
    "\n",
    "6. **Multinomial Naive Bayes**: Probabilistic model assuming feature independence\n",
    "   - **Why?** Fast, works well with text data\n",
    "   - **Assumption**: Features (words) are independent given the class\n",
    "\n",
    "### Why Try Multiple Models?\n",
    "\n",
    "- Different models have different strengths\n",
    "- Performance varies by dataset characteristics\n",
    "- Comparison helps understand which approach works best for Twitter sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classification Models:\n",
      "============================================================\n",
      "\n",
      "1. LinearSVC...\n",
      "   Accuracy: 0.6396\n",
      "\n",
      "2. Logistic Regression...\n",
      "   Accuracy: 0.6439\n",
      "\n",
      "3. SVC with RBF kernel...\n",
      "   Accuracy: 0.6424\n",
      "\n",
      "4. SVC with Linear kernel...\n",
      "   Accuracy: 0.6513\n",
      "\n",
      "============================================================\n",
      "BEST CLASSIFICATION MODEL: SVC_Linear\n",
      "Test Accuracy: 0.6513 (65.13%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test multiple classification models\n",
    "print(\"Testing Classification Models:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. LinearSVC (faster than kernel SVC)\n",
    "print(\"\\n1. LinearSVC...\")\n",
    "linear_svc = LinearSVC(C=0.5, max_iter=2000, random_state=42)\n",
    "linear_svc.fit(X_train_features, y_train_class)\n",
    "y_pred_lsvc = linear_svc.predict(X_test_features)\n",
    "acc_lsvc = accuracy_score(y_test_class, y_pred_lsvc)\n",
    "print(f\"   Accuracy: {acc_lsvc:.4f}\")\n",
    "\n",
    "# 2. Logistic Regression\n",
    "print(\"\\n2. Logistic Regression...\")\n",
    "lr = LogisticRegression(C=1.0, max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_features, y_train_class)\n",
    "y_pred_lr = lr.predict(X_test_features)\n",
    "acc_lr = accuracy_score(y_test_class, y_pred_lr)\n",
    "print(f\"   Accuracy: {acc_lr:.4f}\")\n",
    "\n",
    "# 3. Original SVC with RBF kernel\n",
    "print(\"\\n3. SVC with RBF kernel...\")\n",
    "svc_rbf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svc_rbf.fit(X_train_features, y_train_class)\n",
    "y_pred_rbf = svc_rbf.predict(X_test_features)\n",
    "acc_rbf = accuracy_score(y_test_class, y_pred_rbf)\n",
    "print(f\"   Accuracy: {acc_rbf:.4f}\")\n",
    "\n",
    "# 4. Original Linear SVC\n",
    "print(\"\\n4. SVC with Linear kernel...\")\n",
    "svc_linear = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svc_linear.fit(X_train_features, y_train_class)\n",
    "y_pred_lin = svc_linear.predict(X_test_features)\n",
    "acc_lin = accuracy_score(y_test_class, y_pred_lin)\n",
    "print(f\"   Accuracy: {acc_lin:.4f}\")\n",
    "\n",
    "# Select best model\n",
    "models = [\n",
    "    ('LinearSVC', linear_svc, acc_lsvc),\n",
    "    ('LogisticRegression', lr, acc_lr),\n",
    "    ('SVC_RBF', svc_rbf, acc_rbf),\n",
    "    ('SVC_Linear', svc_linear, acc_lin)\n",
    "]\n",
    "\n",
    "best_name, best_model, best_acc = max(models, key=lambda x: x[2])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"BEST CLASSIFICATION MODEL: {best_name}\")\n",
    "print(f\"Test Accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regression Experiments <a id='section8'></a>\n",
    "\n",
    "### Regression Task Overview\n",
    "\n",
    "**Goal:** Predict continuous sentiment scores in the range [-1.0, 1.0]\n",
    "\n",
    "**Label Mapping:**\n",
    "- Negative sentiment → -1.0\n",
    "- Neutral sentiment → 0.0\n",
    "- Positive sentiment → 1.0\n",
    "\n",
    "**Evaluation Metric:** RMSE (Root Mean Squared Error)\n",
    "- Formula: RMSE = √(Σ(predicted - actual)² / n)\n",
    "- Lower RMSE = better predictions\n",
    "- Penalises large errors more than small errors\n",
    "\n",
    "### Models to Compare\n",
    "\n",
    "1. **LinearSVR (C=0.1)**: Linear Support Vector Regression with strong regularisation\n",
    "   - **Why?** Fast for high-dimensional data\n",
    "   - **C=0.1**: Strong regularisation prevents overfitting\n",
    "\n",
    "2. **LinearSVR (C=1.0)**: Linear SVR with standard regularisation\n",
    "   - **Why?** Baseline configuration\n",
    "\n",
    "3. **Ridge Regression (α=0.5)**: Linear regression with L2 regularisation\n",
    "   - **Why?** Simple, interpretable, closed-form solution\n",
    "   - **α parameter**: Controls strength of regularisation\n",
    "\n",
    "4. **Ridge Regression (α=1.0)**: Ridge with standard regularisation\n",
    "   - **Why?** Commonly used default value\n",
    "\n",
    "5. **SVR (Linear, C=1.0)**: Standard sklearn SVR with linear kernel\n",
    "   - **Why?** Alternative SVR implementation\n",
    "\n",
    "### Why Regression for Sentiment?\n",
    "\n",
    "- Captures **sentiment intensity** (not just positive/negative/neutral)\n",
    "- Useful when sentiment strength matters (\"amazing\" vs \"good\")\n",
    "- Can detect subtle sentiment differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Regression Models:\n",
      "============================================================\n",
      "\n",
      "1. LinearSVR (C=0.1)...\n",
      "   RMSE: 0.5931\n",
      "\n",
      "2. Ridge Regression...\n",
      "   RMSE: 0.5752\n",
      "\n",
      "3. SVR (Linear, C=1.0)...\n",
      "   RMSE: 0.5908\n",
      "\n",
      "============================================================\n",
      "BEST REGRESSION MODEL: Ridge\n",
      "Test RMSE: 0.5752\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test multiple regression models\n",
    "print(\"\\nTesting Regression Models:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Linear SVR with different C\n",
    "print(\"\\n1. LinearSVR (C=0.1)...\")\n",
    "from sklearn.svm import LinearSVR\n",
    "linear_svr = LinearSVR(C=0.1, max_iter=2000, random_state=42)\n",
    "linear_svr.fit(X_train_features, y_train_reg)\n",
    "y_pred_lsvr = linear_svr.predict(X_test_features)\n",
    "rmse_lsvr = np.sqrt(mean_squared_error(y_test_reg, y_pred_lsvr))\n",
    "print(f\"   RMSE: {rmse_lsvr:.4f}\")\n",
    "\n",
    "# 2. Ridge Regression\n",
    "print(\"\\n2. Ridge Regression...\")\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=1.0, random_state=42)\n",
    "ridge.fit(X_train_features, y_train_reg)\n",
    "y_pred_ridge = ridge.predict(X_test_features)\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test_reg, y_pred_ridge))\n",
    "print(f\"   RMSE: {rmse_ridge:.4f}\")\n",
    "\n",
    "# 3. Original SVR\n",
    "print(\"\\n3. SVR (Linear, C=1.0)...\")\n",
    "svr_model = SVR(kernel='linear', C=1.0)\n",
    "svr_model.fit(X_train_features, y_train_reg)\n",
    "y_pred_svr = svr_model.predict(X_test_features)\n",
    "rmse_svr = np.sqrt(mean_squared_error(y_test_reg, y_pred_svr))\n",
    "print(f\"   RMSE: {rmse_svr:.4f}\")\n",
    "\n",
    "# Select best\n",
    "reg_models = [\n",
    "    ('LinearSVR', linear_svr, rmse_lsvr),\n",
    "    ('Ridge', ridge, rmse_ridge),\n",
    "    ('SVR', svr_model, rmse_svr)\n",
    "]\n",
    "\n",
    "best_reg_name, best_reg_model, best_rmse = min(reg_models, key=lambda x: x[2])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"BEST REGRESSION MODEL: {best_reg_name}\")\n",
    "print(f\"Test RMSE: {best_rmse:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Detailed Performance Analysis <a id='section10'></a>\n",
    "\n",
    "### Classification: Per-Class Performance\n",
    "\n",
    "This section provides a detailed breakdown of classification performance by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report:\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.38      0.47       646\n",
      "     neutral       0.64      0.78      0.70      1882\n",
      "    positive       0.69      0.60      0.64      1412\n",
      "\n",
      "    accuracy                           0.65      3940\n",
      "   macro avg       0.65      0.59      0.60      3940\n",
      "weighted avg       0.65      0.65      0.64      3940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from best model\n",
    "if best_name == 'LinearSVC':\n",
    "    final_pred = y_pred_lsvc\n",
    "elif best_name == 'LogisticRegression':\n",
    "    final_pred = y_pred_lr\n",
    "elif best_name == 'SVC_RBF':\n",
    "    final_pred = y_pred_rbf\n",
    "else:\n",
    "    final_pred = y_pred_lin\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test_class, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_env (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
